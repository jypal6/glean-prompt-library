Analysis of Glean Prompt Library: Usage Patterns and Strategic Focus
In this report, we analyze approximately 200 prompts from the Glean prompt library to uncover usage patterns and strategic focus areas  . Each prompt entry includes a description, associated connectors (integrations with data sources or apps), and a prompt type (category). We inferred high-level domains for each connector (e.g. Documents, Communication, Tickets) based on its nature. Below, we present key findings with supporting data and visualizations.
 
Overview and Data Highlights
Cross-functional coverage: The prompts span multiple departments – from Support and Sales to Engineering, Marketing, Finance, Legal, and more. Notably, “All teams” (general use) prompts make up the largest single group (55 out of 184)  , indicating a broad, company-wide applicability. The next largest sets are for Support (26 prompts) and Marketing (25), followed by Sales (22) and Engineering (20) 2 2. Smaller numbers target Finance (16), Legal (9), Security (6), Design (3), and IT Operations (2). This distribution suggests that Glean’s prompt library is intended to be widely useful across departments, with particular emphasis on customer-facing teams (Support, Sales) and content-heavy roles (Marketing).
Connector integration: A striking finding is the breadth of connectors integrated. We identified 44 distinct connectors used across the prompts, ranging from file repositories to communication tools. This broad range of connectors indicates the competing company’s solution is designed to pull information from many different systems – documents, wikis, ticketing systems, code repos, emails, calendars, messaging platforms, etc. In fact, many prompts reference multiple data sources in one query (for example, a single prompt might search Google Drive, OneDrive, Notion, and Dropbox in parallel 2). This suggests a strategic aim of breaking down data silos by enabling the AI assistant to access all major content repositories and apps employees use. Connectors like Google Drive and OneDrive appear in a large share of prompts (79 and 63 prompts respectively), as do Notion (55) and Dropbox (51) 2. This dominance of document storage and knowledge base connectors shows an emphasis on aggregating enterprise knowledge. Popular communication and collaboration tools are also heavily integrated – for example, Slack appears in 25 prompts and Gong (call recordings) in 22 1. Major support ticketing systems (ServiceNow, Zendesk, Freshservice) and CRM tools (Salesforce) are well represented as well 2 2. In short, the competitor’s assistant connects to virtually all types of enterprise data, from files and chats to tickets and code repositories.
Prompt types: Each prompt is categorized by the type of task (we infer this as the “prompt type” or category). The distribution of prompt types reveals where the solution’s functionality is focused. By far the most common category is “Create” – about 40% of prompts are generative tasks where the AI produces new content (e.g. drafting emails, writing summaries or agendas)   3. The next most frequent is “Analyze” (\~17%), which involves analyzing given inputs (e.g. evaluating risks, troubleshooting) 3. “Explore” (open-ended exploration or brainstorming) prompts and “Summarize” prompts each account for roughly 10–16% of the library 3 3. Smaller portions are “Research” (\~8%) and “Search” (\~5%) queries, and a handful of “Onboard” or other types 2 2. This breakdown is significant: nearly half of all prompts involve content creation, indicating a strategic focus on generative AI capabilities (not just information retrieval). The assistant is frequently asked to draft or create outputs (emails, plans, posts, etc.), suggesting the competitor is positioning it as a productivity tool that produces work product, not merely finds information. The prevalence of analytical and summarization tasks further underscores an emphasis on making sense of complex inputs (summarizing documents, analyzing data, etc.).
 
High-Frequency Prompt Areas
One way to gauge the competitor’s priorities is to see which connectors and prompt types are used most often. High-frequency connectors point to the tools and data sources the assistant engages with most, while prompt types reveal the kinds of tasks it’s most commonly asked to perform.
Top Connectors by Usage Frequency
Many prompts integrate with multiple systems, but certain connectors appear especially often. The chart below shows the top 10 most-used connectors across all prompts:
 
Top 10 connectors by prompt volume. Each bar represents the number of prompts (out of 184) that include the given connector. Connectors like Google Drive and OneDrive are by far the most common, reflecting the importance of document repositories in the competitor’s use cases 2. Notion and Coda (knowledge/document collaboration tools) also rank very high, as does Dropbox – together, these indicate a heavy reliance on file and content management systems in the prompt library. We also see Slack (enterprise chat) and Microsoft Teams/Outlook/Gmail (communications) among the top connectors, underscoring that communication and messaging data is a key part of the assistant’s knowledge base 1. Notably, Confluence (a corporate wiki) and Jira (issue/ticket tracker) appear in the top ranks as well – highlighting strong usage of internal knowledge bases and project tracking tools. For example, the prompt “Explain a technical term” is tagged for Confluence, Notion, Jira, and code repos to find relevant explanations 3.
Observation: The dominance of document storage (Google Drive, OneDrive, Box, etc.) and knowledge wiki connectors (Notion, Confluence) suggests the competitor’s assistant is primarily leveraged to retrieve and summarize content from documents. The prominence of Slack and other communication tools alongside those indicates the assistant is expected to combine unstructured conversational data with structured documents. In practice, many prompt templates instruct the AI to search both file repositories and chat logs for answers. This reflects a strategic focus on offering a unified search across an organization’s digital footprint – something the competitor likely views as a key differentiator. It’s also worth noting that all major support ticketing systems (Zendesk, ServiceNow, Freshservice, Nice CXone) appear frequently (collectively in dozens of prompts) 2, which aligns with a concentration of prompts in the Support domain (more on that below). Similarly, Salesforce and call recording tools (Gong) show up in multiple Sales-related prompts 2 2, indicating a conscious effort to support Sales workflows. In short, the tools most integrated in these prompts are those where institutional knowledge resides: company documents, emails/chats, and customer records. This alignment reveals that the competing company’s strategy is to position their AI as an omniscient assistant that can draw from all these sources seamlessly.
Prompt Type Distribution
The prompt library can also be analyzed by the nature of tasks it covers. We identified each prompt’s category (as labeled in the data, e.g. Summarize, Create, Analyze, etc.). The distribution is visualized below:
Distribution of prompt types (categories) in the Glean library. The Create category (green slice) dominates the library, comprising about 40% of all prompts. Analyze and Explore tasks (orange and gray) are the next largest, each around half the share of Create. Summarize tasks (yellow) form \~10–11%, followed by Research (\~8%) and Search (\~5%). A small “Other” segment includes a few uncategorized or mixed-type prompts.
Key insights from prompt types:
•	Content Generation (“Create”) is King: Roughly 3 out of 5 prompts involve generative output (Create or Explore combined). These include drafting emails, writing social media posts, creating agendas, brainstorming ideas, etc. For example, a Marketing prompt asks the AI to “draft a social media post promoting an event” 3 and a Sales prompt has it “draft four email templates for post-sale outreach” 3. The prevalence of creation tasks suggests the competitor is emphasizing productivity and writing assistance. The assistant is not just answering questions, but actually producing work (emails, summaries, plans) that a user might otherwise have to write themselves. This aligns with the general industry trend of positioning AI as a writing assistant, and it likely reflects a strategic bet that helping users create content faster is a high-value use case.
•	Information Synthesis (Summarize & Analyze): A significant portion of prompts (around one-quarter if Summarize and Analyze are combined) involve digestion and analysis of existing information. Summarization prompts ask the AI to condense documents, threads, or support tickets. For instance, “Summarize this customer support ticket” is a common Support prompt 3, and “Summarize the last two docs that person X sent me” is an All-teams prompt for quick catch-up 3. Analytical prompts have the assistant reviewing content to extract insights or check criteria (e.g. “Analyze the impact of this regulation on our product” 3 or “Assess potential risks in a project document” for Finance 3). The prominence of these tasks indicates a focus on using AI to save users time in reading and interpreting information. It also implies the competitor sees value in AI expertise augmentation – helping professionals make sense of complex data (like legal docs, product specs, or logs) quickly and accurately.
•	Retrieval and Research: A smaller but notable set of prompts are pure search or research tasks (\~13% combined). These include things like searching for references (e.g. “Does Document X mention Topic Y?” 3) and open-ended research (“find top assets on Topic Z and summarize them” 3). That such prompts exist shows the assistant is used as an advanced search engine for internal data. However, the relatively lower share of “Search” category prompts (only 10 out of 184 were labeled purely as Search) suggests that straightforward Q\&A or lookup might not be the primary selling point – instead, those needs may be met by existing search, while the AI is reserved for more complex, multi-step queries and generative tasks.
•	Onboarding and Training: There are a few specialized categories like “Onboard” (only 1 prompt) and a mix of “Create & Summarize” or other combos. For example, there is one onboarding prompt “Get started writing code for a new feature” that guides a developer to relevant docs and codebases 3. There’s also a prompt for creating a training quiz for support agents 3. These are relatively rare, but their presence indicates the assistant is also envisioned as a tool for learning and development, helping new employees or aiding knowledge transfer.
In summary, the competitor’s prompt usage skews heavily towards proactive content generation and intelligent summarization, with traditional search queries being a smaller part. This pattern strongly implies a strategic focus on making the AI a productivity driver (by writing, summarizing, and analyzing on the user’s behalf) rather than just a passive information fetcher.
Connector Domains and Usage Patterns
To better understand how these connectors serve different use cases, we grouped the 44 connectors into broader domains:
•	Documents & Knowledge Repositories: File storage and content management (e.g. Google Drive, OneDrive, Dropbox, Box), collaboration docs (Notion, Coda, Confluence, Guru, Slab), and content libraries (Brightspot, Bynder).
•	Communication & Collaboration: Chat and email systems (e.g. Slack, Microsoft Teams, Gmail, Outlook), meeting/call platforms (e.g. Gong for call transcripts, Google Calendar).
•	Support & Ticketing: Helpdesk and ticketing tools (e.g. Zendesk, ServiceNow, Freshservice, Nice CXone).
•	Project Management & DevOps: Task and issue trackers (e.g. Jira, Asana, Monday, Linear).
•	Code Repositories: Source code platforms (e.g. GitHub, GitLab, Bitbucket).
•	CRM & Sales Enablement: Customer relationship and sales content systems (e.g. Salesforce, Seismic, Highspot).
•	HR & Intranet: HR systems (Workday, BambooHR) and internal portals (LumApps, Simpplr, Interact).
•	Other: Web search and LLM-trained internal data (when no specific connector is needed), plus design tools (Miro, InVision, Zeplin for a few Design prompts).
Below, we highlight usage patterns in these domains:
 
Documents as the backbone: Virtually all prompts involve document/knowledge connectors in some way. The Documents domain (Google Drive, OneDrive, Notion, etc.) is by far the most frequently invoked – these connectors collectively occur hundreds of times in the prompt set. For example, a Finance prompt to “Summarize contract” explicitly lists five document repositories (Coda, Dropbox, Google Drive, Notion, OneDrive) as sources 3. Many prompts are similarly broad, indicating the assistant should search any and all documents available to answer the query. This strategy tells us the competitor assumes that relevant information is often stored in files (documents, slides, wikis) and that a key value of their AI is to retrieve and synthesize that info. By making document connectors ubiquitous, the assistant can answer questions like “Align documents to new accounting standards” by searching across multiple repositories at once 3. In practice, this means Glean is positioning itself as a unified enterprise search as well as an AI agent – the prompts lean on heavy retrieval from document storage, then often ask the AI to do something with that content (summarize it, extract insights, etc.). The strategic implication is that the company sees its differentiation in being able to bridge all knowledge stores (as opposed to relying on users to know where to look).
Communication data integrated: The presence of connectors like Slack and Microsoft Teams (chat), as well as email (Gmail, Outlook), in many prompts shows that communications are a significant data source for this assistant. For instance, a prompt for Sales asks to “prepare me for my meeting by summarizing our last Gong call and relevant Slack notes”, explicitly pulling from Slack messages and call transcripts 3. Another prompt searches Slack for recent mentions of a topic 3. By integrating chat and email, the assistant can answer questions like “Who did I talk to about XYZ on Slack?” 3 or compile updates from emails. This reflects a recognition that a lot of organizational knowledge is in conversations, not just in docs. Strategically, incorporating communications suggests the competitor aims to embed the AI in daily workflow – e.g., catching up on Slack threads, drafting email replies – which could drive user engagement. It also positions the assistant as a tool for knowledge workers who spend time in meetings and messaging (providing value by summarizing or extracting action items from those interactions). By supporting communication channels, Glean’s solution tries to be holistic: not only answering direct queries, but also helping manage the deluge of messages and meetings professionals face (for example, there are prompts for “summarize this Slack thread” 3 and “what was said about in Slack and Jira over the past month” 3).
Support and ticketing systems: A significant cluster of prompts is dedicated to customer support scenarios. The assistant is asked to summarize support tickets, draft responses, and identify trends in tickets. These prompts often list Zendesk, ServiceNow, and others together, meaning the AI can unify data across support channels 3. For example, “Find tickets that mention \error message]” will search recent tickets in all support systems and then summarize common themes[2. Another prompt, “Escalation Management,” has the AI pull any escalated support tickets for an account from multiple sources 3. The inclusion of multiple support tools in single prompts likely exists because different customers (or different teams) use different systems – but Glean’s library provides a template that works regardless of which one the customer has. This highlights a strategic focus on customer support use cases: they anticipate their AI will be used heavily by support agents or managers to get quick overviews of customer issues. It’s a savvy focus area since improving support efficiency (through AI summaries, suggested replies, etc.) has tangible ROI for companies. By showcasing prompts that integrate support platforms, the competitor is signaling that their solution can reduce resolution times and improve support quality by learning from past tickets and knowledge base articles (indeed, prompts like “draft a support email using knowledge base articles” are provided 3). This likely aligns with a go-to-market focus on support teams as early adopters.
Project management and dev tools: Connectors like Jira (issues) and GitHub (code) appear, though less frequently than docs or support tools. Engineering-focused prompts exist (e.g. “Summarize all open Jira tickets assigned to me” 3, “Code review for security issues” 3). These indicate the assistant is also intended to help with developer productivity (summarizing code changes, listing who worked on a feature 3, or debugging errors using past bug tickets 3). The relatively smaller number of these prompts suggests that while the capability is there, it may not be the primary selling point. Still, from a strategic perspective, including them rounds out the image of a comprehensive tool that even engineers can use to sift through technical information – reinforcing that the product is not just for “business” users but also technical users. It may also be a competitive response to other tools that focus on coding assistance; Glean can claim some coverage of that via these prompts.
CRM and sales enablement: Salesforce appears in around 10 prompts, often alongside other tools. There are prompts to summarize Salesforce opportunities that mention a competitor 3, to recap customer meetings pulling data from Salesforce and email/calendar 3, and to draft outreach emails using Highspot/Seismic content 3. Clearly, sales teams are another target audience. By integrating CRM data, the assistant can answer “What’s the status of this customer or deal?” by aggregating updates (one prompt does exactly that – “summary of customer status” combining Salesforce, Gong call info, etc. 3). The strategic intention here is to provide sales intelligence and prep, helping salespeople quickly get up to speed on accounts and craft communications. This aligns with competitor positioning as a revenue team assistant (a number of prompts are explicitly sales-oriented, like competitor research, objection handling, and crafting LinkedIn outreach). It shows the competitor’s focus on high-impact roles: after support, sales is another area where AI assistance can directly influence outcomes (faster deal cycles, personalized outreach). We can infer that Glean’s strategy involves targeting these departments to drive adoption.
Internal knowledge portals and HR: Connectors such as Workday and BambooHR (HR systems) and LumApps/Slab (intranet/wiki) appear in a few prompts, mainly those about finding company policy info 3 or learning about a team 3. While these are not as common, their presence indicates the assistant is also pitched as a tool for internal reference and onboarding (answering “Where can I find X policy” or “What does the Y team do”). It’s part of a “whole company” narrative – even if HR or corporate communications use cases aren’t the core drivers, having prompts for them allows the vendor to say “our AI helps every employee, whether it’s an engineer troubleshooting code or an employee looking up HR policy.” This breadth can be a selling point to enterprise buyers who want a one-stop solution. Strategically, it positions the competitor as comprehensive: not just a sales or support assistant, but an all-purpose workplace assistant.
In summary, the connector usage patterns show a deliberate wide net cast by the competing company: they ensure their assistant touches all key categories of enterprise data. However, within that wide coverage, the depth of prompts is especially notable in documents, support, sales, and communications. This suggests those are the areas they expect the AI to be used most and where they likely see the strongest demand or competitive advantage.
Emerging Themes and Strategic Insights
Bringing these findings together, we can discern several strategic themes about Glean’s focus:
•	1. Emphasis on Content Creation & Synthesis: The disproportionate number of Create prompts (writing tasks) implies that Glean is positioning its Copilot not just as a Q\&A bot, but as a proactive content generator. This aligns with a strategy to deliver direct business value – drafting emails, documents, and plans saves users time. For example, prompts for crafting social posts or outreach emails show an intent to help marketing and sales teams produce output quickly 3 3. By focusing on creation and synthesis (which together make up well over half of the prompts), the competitor is likely aiming to differentiate on productivity gains. In essence, the AI doesn’t just answer questions; it does work. This is a key strategic bet in the enterprise AI space – that companies will pay for tools that act as junior team members (writing first drafts of content, preparing summaries, etc.). Glean’s library reflects this bet.
•	2. Cross-Functional Support with Focus on Support & Sales: Glean’s prompt coverage across many departments indicates a horizontal (cross-industry, cross-role) strategy, but within that, Customer Support and Sales are clear focal points. Many prompts are tailored to support agents (ticket summaries, customer sentiment analysis, escalation tracking) 3 3, and to sales reps or sales engineers (meeting prep, opportunity insights, objection handling) 3 3. This dual focus makes sense: Support and Sales are customer-facing functions where improved efficiency and intelligence can directly impact revenue or customer satisfaction. By providing a lot of out-of-the-box prompts for these areas, the competitor is likely trying to accelerate adoption in teams that can quickly demonstrate ROI. For instance, a support team using AI to answer tickets faster, or a sales team closing more deals with AI research, are compelling success stories. The strategic hypothesis is that winning in Support and Sales use cases will drive broader enterprise adoption. In the prompt library, we see evidence of this hypothesis – e.g., multiple prompts that mine CRM and support data for insights, something likely meant to showcase how the AI can increase win rates or reduce support backlog.
•	3. Unified Knowledge Retrieval (Breaking Silos): The way connectors are used reveals that Glean’s strategy heavily leans on being an integrated knowledge hub. Many prompts explicitly pull data from a variety of systems simultaneously – which is a selling point that their AI can combine information no human easily could. Having, for example, a single prompt query Slack, Google Drive, and Salesforce together 3 demonstrates a capability to synthesize across silos. Strategically, this addresses a common pain point in enterprises: information is scattered. Glean appears to be tackling this by ensuring its AI has “eyes and ears” in all major platforms. The insight here is that the competitor isn’t positioning their Copilot as just an intelligent chat on top of one dataset, but rather as an enterprise-wide intelligence layer. This is likely intended to set them apart from point solutions (like a chatbot only for Salesforce or only for Slack). Moreover, it indicates an upsell strategy: the more connectors a customer enables, the more valuable the assistant becomes. The library’s prompts encourage using multiple connectors at once, implicitly showing customers the benefit of turning on all integrations to get the richest answers.
•	4. Driving User Engagement through Broad Utility: The inclusion of prompts that are not strictly “work tasks” – for example, asking about work-life balance or career growth books – is an interesting strategic choice. These prompts (which often use only the LLM or web search, and have no enterprise connector) suggest the competitor wants their assistant to be used frequently, for a wide array of questions 3 3. By catering to general professional development queries (like productivity tips, burnout advice 3, or even ice-breaker questions for team meetings 3), Glean’s AI can remain useful even when the user isn’t querying company data. This breadth can increase adoption and habituation – if users start turning to the AI for everyday questions (even personal ones like “give me public speaking tips” 3), they are more likely to integrate it into their workflow. The strategy behind this could be to boost overall usage, making the tool feel more like an ever-present “assistant” rather than a niche tool. In a competitive sense, this edges into the territory of generic AI assistants (like ChatGPT or Bing Chat), which employees might otherwise use for these questions. By providing those capabilities internally, the company can keep usage within its platform (and perhaps alleviate security concerns of employees using external AI for work questions). Essentially, Glean is trying to capture that share of usage by saying: ask our Copilot, it can help with anything. This reinforces the narrative of a universal assistant for the workplace.
•	5. Broad Coverage as a Competitive Strategy: Compared to some competitors that might focus deeply on one vertical, Glean’s prompt set is broad but relatively shallow in each area (a dozen prompts for sales, rather than hundreds only for sales, for instance). This suggests a strategy to cover “all the bases” to compete as an all-in-one solution. They likely position themselves against both point solutions and other broad copilots by saying they have pre-built expertise in every department. For example, having even a few design prompts with Figma or Miro connectors 3 means they can claim support for design teams, even if that’s not a primary use case. This one-stop-shop approach is strategic in enterprise sales – many decision-makers will prefer a single AI platform for the company rather than different tools for each team. The prompt library’s diversity is evidence that Glean is deliberately building that holistic narrative. It’s likely not a coincidence that their website (as per our data) highlights solutions for “All teams” 1. The prompt library serves as both a functional catalog and a marketing instrument to show breadth.
•	6. Focus on Value-Driving Use Cases: Within the broad coverage, the concentration of prompts in certain areas (like support ticket handling or sales meeting prep) indicates the competitor knows where AI can drive clear value. These use cases (summarizing a deluge of support tickets, or equipping a salesperson with quick insights) have direct impact – faster customer support resolution, or more personalized sales pitches. The strategic insight is that Glean is prioritizing such high-impact scenarios to increase the likelihood of success stories. If their Copilot can demonstrably save time for support agents or help close a deal, those wins justify investment. The presence of prompts like “Customer Health Summary” (aggregating interactions and red flags for an account) 3 and “Escalation Management” 3 shows a focus on proactive insights that managers and customer success teams would value. This aligns with a strategy of targeting pain points that leadership cares about: improving customer experience, reducing manual work, and surfacing insights from data. The prompt library is essentially a reflection of a use-case driven strategy – covering the specific scenarios where an AI assistant can shine.
Hypotheses about strategic focus: Based on this analysis, it appears the competing company (Glean) is strategically focusing on being an enterprise-wide copilot with particular strength in knowledge-intensive and customer-facing tasks. They are likely betting on the following:
•	Broad Adoption: By providing prompts for virtually every department, they aim to drive adoption across the whole organization, positioning the tool as a company-wide productivity assistant rather than a niche tool. This broad approach is evident from the “all teams” orientation of the library 1.
•	Key Departmental Beachheads: Within that breadth, they are zeroing in on Support and Sales as critical early adopters where the ROI of AI is tangible. They likely see those as beachheads to expand into other departments. The heavy content for support and sales implies those are considered primary drivers for the product (e.g., solving the support ticket backlog or accelerating sales cycles as marquee use cases).
•	Knowledge Silo Bridging: A core value proposition is enabling users to get answers drawing from all enterprise data. Strategically, this means they compete on the ability to search and synthesize across platforms – something clearly reflected by multi-connector prompts and the emphasis on integrated connectors. They likely pitch that their AI “knows everything your company knows” by virtue of these connectors, which is a strong message to customers dealing with fragmented information systems.
•	Productivity & Efficiency: The nature of prompts (lots of summarization, drafting, and analysis) suggests the strategic goal of saving employees time on routine but time-consuming tasks. This aligns with marketing an AI copilot as a way to increase efficiency (e.g., “Copilot handles the busywork, you focus on high-level work”). The presence of prompts that prepare meeting notes, summarize weekly updates 3, or generate reports indicates a focus on automation of knowledge work.
•	Encouraging Everyday Use: By answering not just work-specific queries but also general questions (like how to improve time management 3), Glean’s strategy likely includes making their assistant something employees turn to frequently. This drives engagement and internal value; if an employee uses the assistant daily (even for small questions), it becomes ingrained in workflows. This could increase the perceived indispensability of the product.
Overall, the prompt data portrays a competitor strategy of a comprehensive, integration-rich AI assistant aimed at improving knowledge worker productivity across the board, with special attention to high-value verticals (support, sales) and a clear focus on content generation and summarization as killer features. In a competitive context, this means Glean is not trying to be an expert only in one area, but rather a platform that can be adopted company-wide – a direct competitor to offerings like Microsoft 365 Copilot, but as an independent vendor. The heavy inclusion of connectors for third-party apps (Slack, Google Drive, etc.) also suggests they are targeting companies with heterogeneous tool stacks, positioning themselves as the connective tissue that Microsoft’s or others' copilots might not provide out-of-the-box.
In conclusion, the usage patterns in Glean’s prompt library support the hypothesis that their strategic focus is on breadth of capability and depth of knowledge integration, aimed at becoming a ubiquitous AI assistant in their customers’ organizations. By covering a wide range of scenarios (from drafting a blog post to troubleshooting a login issue), they signal to potential customers that “no matter your question or role, our Copilot can help”. This comprehensive approach, coupled with targeted high-impact use cases, likely reflects Glean’s plan to compete in the burgeoning enterprise AI assistant market by offering an experience that is both wide-ranging and deeply integrated into the daily tasks that matter for business success 1 1.
